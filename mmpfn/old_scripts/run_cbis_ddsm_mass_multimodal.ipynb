{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8292ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "/home/wall/anaconda3/envs/mmpfn2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os \n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from mmpfn.datasets.cbis_ddsm import CBISDDSMDataset\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from mmpfn.models.mmpfn import MMPFNClassifier\n",
    "from mmpfn.models.mmpfn.constants import ModelInterfaceConfig\n",
    "from mmpfn.models.mmpfn.preprocessing import PreprocessorConfig\n",
    "from mmpfn.scripts_finetune_mm.finetune_tabpfn_main import fine_tune_mmpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb308ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd5c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embeddings from embeddings/cbis_ddsm/mass_test_all.pt\n",
      "Load embeddings from embeddings/cbis_ddsm/mass_train_all.pt\n"
     ]
    }
   ],
   "source": [
    "# data_path = os.path.join(os.getenv('HOME'), \"workspace/works/tabular_image/MultiModalPFN/mmpfn/data/cbis_ddsm\")\n",
    "data_path = os.path.join(os.getenv('HOME'), \"works/research/MultiModalPFN/mmpfn/data/cbis_ddsm\")\n",
    "\n",
    "kind = 'mass'  # mass calc\n",
    "image_type = 'all' # all full crop roi\n",
    "test_dataset = CBISDDSMDataset(data_path=data_path, data_name=f'csv/{kind}_case_description_test_set.csv', kind=kind, image_type=image_type)\n",
    "# _ = test_dataset.get_images()\n",
    "_ = test_dataset.get_embeddings(mode='test')\n",
    "train_dataset = CBISDDSMDataset(data_path=data_path, data_name=f'csv/{kind}_case_description_train_set.csv', kind=kind, image_type=image_type)\n",
    "# _ = train_dataset.get_images()\n",
    "_ = train_dataset.get_embeddings(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:  19%|█▉        | 19/100 [00:07<00:32,  2.48it/s, Best Val. Loss=0.249, Best Val. Score=-0.249, Training Loss=0.399, Val. Loss=0.249, Patience=32, Utilization=0, Grad Norm=4.67][2025-09-12 23:42:18,929] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  22%|██▏       | 22/100 [00:08<00:27,  2.86it/s, Best Val. Loss=0.249, Best Val. Score=-0.249, Training Loss=0.307, Val. Loss=0.25, Patience=30, Utilization=0, Grad Norm=8.19] [2025-09-12 23:42:19,840] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:35,  2.79it/s, Best Val. Loss=0.249, Best Val. Score=-0.249, Training Loss=0.296, Val. Loss=0.268, Patience=-48, Utilization=0, Grad Norm=5.01]                         \n",
      "[2025-09-12 23:42:46,959] INFO - Initial Validation Loss: 0.27744797343325245 Best Validation Loss: 0.248988481589646 Total Steps: 101 Best Step: 18 Total Time Spent: 36.65427112579346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6851851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   4%|▍         | 4/100 [00:01<00:50,  1.90it/s, Best Val. Loss=0.268, Best Val. Score=-0.268, Training Loss=0.342, Val. Loss=0.268, Patience=47, Utilization=0, Grad Norm=4.19]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     21\u001b[0m save_path_to_fine_tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mmpfn_pad_ufes_20.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mfine_tune_mmpfn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# path_to_base_model=\"auto\",\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Finetuning HPs\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetuning_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Input Data\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use \"cpu\" if you don't have a GPU\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_training_curve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows a final report after finetuning.\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows all logs, higher values shows less\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze the input layers (encoder and y_encoder) during finetuning\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMGM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# MGM MGM+CAP\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgm_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcap_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# disables preprocessing at inference time to match fine-tuning\u001b[39;00m\n\u001b[1;32m     47\u001b[0m no_preprocessing_inference_config \u001b[38;5;241m=\u001b[39m ModelInterfaceConfig(\n\u001b[1;32m     48\u001b[0m     FINGERPRINT_FEATURE\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m     PREPROCESS_TRANSFORMS\u001b[38;5;241m=\u001b[39m[PreprocessorConfig(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/finetune_tabpfn_main.py:423\u001b[0m, in \u001b[0;36mfine_tune_mmpfn\u001b[0;34m(mixer_type, mgm_heads, cap_heads, path_to_base_model, save_path_to_fine_tuned_model, time_limit, finetuning_config, validation_metric, categorical_features_index, task_type, device, y_train, X_train, image_train, use_multiple_gpus, multiple_device_ids, X_val, y_val, random_seed, logger_level, show_training_curve, freeze_input)\u001b[0m\n\u001b[1;32m    421\u001b[0m optimizer\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 423\u001b[0m     validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_tabpfn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     validation_score \u001b[38;5;241m=\u001b[39m validation_metric\u001b[38;5;241m.\u001b[39mconvert_error_to_score(\n\u001b[1;32m    425\u001b[0m         validation_loss\n\u001b[1;32m    426\u001b[0m     )\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# -- Check tuning state\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# is_best = validation_loss < best_validation_loss\u001b[39;00m\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/training_utils/validation_utils.py:137\u001b[0m, in \u001b[0;36mvalidate_tabpfn\u001b[0;34m(X_train, image_train, y_train, X_val, image_val, y_val, validation_metric, model, model_forward_fn, task_type, device)\u001b[0m\n\u001b[1;32m    133\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_val\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m TaskType\u001b[38;5;241m.\u001b[39mMULTICLASS_CLASSIFICATION:\n\u001b[1;32m    135\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    136\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_logits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_val\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_scores, auc_ovrs, auc_ovos = [], [], []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    X_train = train_dataset.x\n",
    "    y_train = train_dataset.y\n",
    "    X_test = test_dataset.x\n",
    "    y_test = test_dataset.y\n",
    "    image_train = train_dataset.embeddings\n",
    "    image_test = test_dataset.embeddings\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_pad_ufes_20.ckpt\"\n",
    "    \n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=pd.DataFrame(X_train),\n",
    "        image_train=image_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM+CAP', # MGM MGM+CAP\n",
    "        mgm_heads=8,\n",
    "        cap_heads=4,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM+CAP', # no_append token_append split_append multihead\n",
    "        mgm_heads=8,\n",
    "        cap_heads=4,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(X_train, image_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(X_test, image_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)\n",
    "    \n",
    "    # auc_ovr = roc_auc_score(y_test, clf_finetuned.predict_proba(X_test, image_test), multi_class='ovr')\n",
    "    # auc_ovrs.append(auc_ovr)\n",
    "    \n",
    "    # auc_ovo = roc_auc_score(y_test, clf_finetuned.predict_proba(X_test, image_test), multi_class='ovo')\n",
    "    # auc_ovos.append(auc_ovo)c:\\Users\\SuyeonWall\\Downloads\\breast-cancer-imageclassification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ovr = np.mean(auc_ovrs)\n",
    "# std_ovr = np.std(auc_ovrs)\n",
    "\n",
    "# mean_ovo = np.mean(auc_ovos)\n",
    "# std_ovo = np.std(auc_ovos)\n",
    "\n",
    "# print(\"Mean AUC OVR:\", mean_ovr)\n",
    "# print(\"Std AUC OVR:\", std_ovr)\n",
    "# print(\"Mean AUC OVO:\", mean_ovo)\n",
    "# print(\"Std AUC OVO:\", std_ovo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpfn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
