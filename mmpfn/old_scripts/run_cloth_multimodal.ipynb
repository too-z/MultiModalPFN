{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb31173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wall/anaconda3/envs/mmpfn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from mmpfn.datasets.cloth import ClothDataset\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mmpfn.models.mmpfn import MMPFNClassifier\n",
    "from mmpfn.models.mmpfn.constants import ModelInterfaceConfig\n",
    "from mmpfn.models.mmpfn.preprocessing import PreprocessorConfig\n",
    "from mmpfn.scripts_finetune_mm.finetune_tabpfn_main import fine_tune_mmpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb73c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a312084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embeddings from embeddings/cloth/cloth.pt\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getenv('HOME'), \"works/research/MultiModalPFN/mmpfn/data/cloth\")\n",
    "dataset = ClothDataset(data_path)\n",
    "_ = dataset.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dce1ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     25\u001b[0m save_path_to_fine_tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mmpfn_airbnb.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mfine_tune_mmpfn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# path_to_base_model=\"auto\",\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Finetuning HPs\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetuning_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Input Data\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use \"cpu\" if you don't have a GPU\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_training_curve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows a final report after finetuning.\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows all logs, higher values shows less\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze the input layers (encoder and y_encoder) during finetuning\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMGM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# MGM MGM+CQAM\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgm_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcqam_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# disables preprocessing at inference time to match fine-tuning\u001b[39;00m\n\u001b[1;32m     51\u001b[0m no_preprocessing_inference_config \u001b[38;5;241m=\u001b[39m ModelInterfaceConfig(\n\u001b[1;32m     52\u001b[0m     FINGERPRINT_FEATURE\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m     PREPROCESS_TRANSFORMS\u001b[38;5;241m=\u001b[39m[PreprocessorConfig(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     54\u001b[0m )\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/finetune_tabpfn_main.py:319\u001b[0m, in \u001b[0;36mfine_tune_mmpfn\u001b[0;34m(mixer_type, mgm_heads, cqam_heads, path_to_base_model, save_path_to_fine_tuned_model, time_limit, finetuning_config, validation_metric, categorical_features_index, task_type, device, y_train, X_train, image_train, use_multiple_gpus, multiple_device_ids, X_val, y_val, random_seed, logger_level, show_training_curve, freeze_input)\u001b[0m\n\u001b[1;32m    317\u001b[0m optimizer\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 319\u001b[0m     best_validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_tabpfn_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Initial validation loss\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     best_validation_score \u001b[38;5;241m=\u001b[39m validation_metric\u001b[38;5;241m.\u001b[39mconvert_error_to_score(\n\u001b[1;32m    323\u001b[0m         best_validation_loss\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m adaptive_es\u001b[38;5;241m.\u001b[39mupdate(cur_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, is_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/training_utils/validation_utils.py:102\u001b[0m, in \u001b[0;36mvalidate_tabpfn\u001b[0;34m(X_train, image_train, y_train, X_val, image_val, y_val, validation_metric, model, model_forward_fn, task_type, device)\u001b[0m\n\u001b[1;32m     99\u001b[0m     image_train \u001b[38;5;241m=\u001b[39m image_train\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m     image_val \u001b[38;5;241m=\u001b[39m image_val\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 102\u001b[0m pred_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_for_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m task_type:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m TaskType\u001b[38;5;241m.\u001b[39mREGRESSION:\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/finetune_tabpfn_main.py:558\u001b[0m, in \u001b[0;36m_model_forward\u001b[0;34m(model, X_train, y_train, X_test, image_train, image_test, n_classes, softmax_temperature, categorical_features_index, use_autocast, forward_for_validation, device, outer_loop_autocast, is_data_parallel)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39mdevice, enabled\u001b[38;5;241m=\u001b[39muse_autocast):\n\u001b[0;32m--> 558\u001b[0m         pred_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m    561\u001b[0m     pred_logits \u001b[38;5;241m=\u001b[39m pred_logits[:, :, :n_classes]\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/transformer.py:488\u001b[0m, in \u001b[0;36mPerFeatureTransformer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m test_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m         image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((image, test_image), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    491\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/transformer.py:768\u001b[0m, in \u001b[0;36mPerFeatureTransformer._forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(encoder_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(encoder_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m--> 768\u001b[0m         correlation_matrix_avg[i][j] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(16, 8))\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# ax = sns.heatmap(\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m#     correlation_matrix_avg,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m \n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# If we are using a decoder\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    train_len = int(len(dataset) * 0.8)\n",
    "    test_len = len(dataset) - train_len\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "    X_train = train_dataset.dataset.x[train_dataset.indices]\n",
    "    y_train = train_dataset.dataset.y[train_dataset.indices]\n",
    "    X_test = test_dataset.dataset.x[test_dataset.indices]\n",
    "    y_test = test_dataset.dataset.y[test_dataset.indices]\n",
    "    text_train = train_dataset.dataset.embeddings[train_dataset.indices]\n",
    "    text_test = test_dataset.dataset.embeddings[test_dataset.indices]\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_cloth.ckpt\"\n",
    "\n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=pd.DataFrame(X_train),\n",
    "        image_train=text_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM', # MGM MGM+CQAM\n",
    "        mgm_heads=128,\n",
    "        cqam_heads=4,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM', # MGM MGM+CQAM\n",
    "        mgm_heads=128,\n",
    "        cqam_heads=4,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(X_train, text_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(X_test, text_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
