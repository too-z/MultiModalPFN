{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8292ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wall/anaconda3/envs/mmpfn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os \n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from mmpfn.datasets.cloth import ClothDataset\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mmpfn.models.mmpfn_v2 import MMPFNClassifier\n",
    "from mmpfn.models.mmpfn_v2.constants import ModelInterfaceConfig\n",
    "from mmpfn.models.mmpfn_v2.preprocessing import PreprocessorConfig\n",
    "from mmpfn.scripts_finetune_mm.finetune_tabpfn_main import fine_tune_mmpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd5c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embeddings from embeddings/cloth/cloth.pt\n"
     ]
    }
   ],
   "source": [
    "# data_path = os.path.join(os.getenv('HOME'), \"workspace/works/tabular_image/MultiModalPFN/mmpfn/data/cloth\")\n",
    "data_path = os.path.join(os.getenv('HOME'), \"works/research/MultiModalPFN/mmpfn/data/cloth\")\n",
    "dataset = ClothDataset(data_path)\n",
    "_ = dataset.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297dfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGM 1\n",
    "# Mean Accuracy: 0.5998674326115776\n",
    "# Std Accuracy: 0.006042772572327586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4921be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 00:56:50,303] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [13:47,  8.28s/it, Best Val. Loss=0.84, Best Val. Score=-0.84, Training Loss=0.879, Val. Loss=0.84, Patience=-49, Utilization=0, Grad Norm=0.845]                           \n",
      "[2025-09-21 01:10:32,382] INFO - Initial Validation Loss: 1.226486097523351 Best Validation Loss: 0.8397275896332557 Total Steps: 101 Best Step: 100 Total Time Spent: 832.5075809955597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6380910296067167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 01:11:21,455] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   2%|▏         | 2/100 [00:05<09:19,  5.71s/it, Best Val. Loss=1.24, Best Val. Score=-1.24, Training Loss=1.25, Val. Loss=1.24, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 01:11:27,259] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [13:38,  8.19s/it, Best Val. Loss=0.859, Best Val. Score=-0.859, Training Loss=0.898, Val. Loss=0.859, Patience=-48, Utilization=0, Grad Norm=1.28]                         \n",
      "[2025-09-21 01:24:54,677] INFO - Initial Validation Loss: 1.2396382165848059 Best Validation Loss: 0.85908805863119 Total Steps: 101 Best Step: 100 Total Time Spent: 821.5920803546906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6447193990278391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 01:25:42,891] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   2%|▏         | 2/100 [00:05<09:18,  5.70s/it, Best Val. Loss=1.34, Best Val. Score=-1.34, Training Loss=1.27, Val. Loss=1.34, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 01:25:48,686] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   3%|▎         | 3/100 [00:11<09:18,  5.76s/it, Best Val. Loss=1.34, Best Val. Score=-1.34, Training Loss=1.26, Val. Loss=1.34, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 01:25:54,450] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [13:32,  8.12s/it, Best Val. Loss=0.859, Best Val. Score=-0.859, Training Loss=0.909, Val. Loss=0.859, Patience=-47, Utilization=0, Grad Norm=1.91]                         \n",
      "[2025-09-21 01:39:09,524] INFO - Initial Validation Loss: 1.335107493382765 Best Validation Loss: 0.8592182976138714 Total Steps: 101 Best Step: 100 Total Time Spent: 814.9311418533325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6303579319487406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 01:39:58,130] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [13:37,  8.17s/it, Best Val. Loss=0.858, Best Val. Score=-0.858, Training Loss=0.886, Val. Loss=0.858, Patience=-49, Utilization=0, Grad Norm=1.38]                         \n",
      "[2025-09-21 01:53:29,871] INFO - Initial Validation Loss: 1.214977630950318 Best Validation Loss: 0.8581024257558638 Total Steps: 101 Best Step: 100 Total Time Spent: 820.0435707569122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.638753866548829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 01:54:18,107] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   2%|▏         | 2/100 [00:05<09:16,  5.68s/it, Best Val. Loss=1.26, Best Val. Score=-1.26, Training Loss=1.24, Val. Loss=1.26, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 01:54:23,920] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [13:38,  8.19s/it, Best Val. Loss=0.859, Best Val. Score=-0.859, Training Loss=0.885, Val. Loss=0.859, Patience=-48, Utilization=0, Grad Norm=2.34]                         \n",
      "[2025-09-21 02:07:51,207] INFO - Initial Validation Loss: 1.258643369487801 Best Validation Loss: 0.8585917368111191 Total Steps: 101 Best Step: 100 Total Time Spent: 821.3760113716125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6283694211224039\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    train_len = int(len(dataset) * 0.8)\n",
    "    test_len = len(dataset) - train_len\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "    X_train = train_dataset.dataset.x[train_dataset.indices]\n",
    "    y_train = train_dataset.dataset.y[train_dataset.indices]\n",
    "    X_test = test_dataset.dataset.x[test_dataset.indices]\n",
    "    y_test = test_dataset.dataset.y[test_dataset.indices]\n",
    "    image_train = train_dataset.dataset.embeddings[train_dataset.indices]#.unsqueeze(1)\n",
    "    image_test = test_dataset.dataset.embeddings[test_dataset.indices]#.unsqueeze(1)\n",
    "\n",
    "    # if image_type == 'cls':\n",
    "    #     image_train = image_train.unsqueeze(1)\n",
    "    #     image_test = image_test.unsqueeze(1)\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_pad_ufes_20.ckpt\"\n",
    "    \n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=None,\n",
    "        image_train=image_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM+CQAM', # MGM, MGM+CQAM\n",
    "        mgm_heads=16,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM+CQAM', # MGM, MGM+CQAM\n",
    "        mgm_heads=16,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(None, image_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(None, image_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2242065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6360583296509058\n",
      "Std Accuracy: 0.005967005268189257\n"
     ]
    }
   ],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b1026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps: 101it [25:34, 15.35s/it, Best Val. Loss=0.813, Best Val. Score=-0.813, Training Loss=0.842, Val. Loss=0.813, Patience=-50, Utilization=0, Grad Norm=0.915]                         \n",
      "[2025-09-21 02:34:12,529] INFO - Initial Validation Loss: 1.1488419810416064 Best Validation Loss: 0.8129818799517735 Total Steps: 101 Best Step: 100 Total Time Spent: 1537.8710236549377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.643172779496244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps: 101it [25:10, 15.10s/it, Best Val. Loss=0.838, Best Val. Score=-0.838, Training Loss=0.84, Val. Loss=0.838, Patience=-50, Utilization=0, Grad Norm=1.21]                           \n",
      "[2025-09-21 03:01:17,810] INFO - Initial Validation Loss: 1.161577433740172 Best Validation Loss: 0.8375542915552114 Total Steps: 101 Best Step: 100 Total Time Spent: 1513.7210013866425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6586389748121962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps: 101it [26:44, 16.04s/it, Best Val. Loss=0.813, Best Val. Score=-0.813, Training Loss=0.873, Val. Loss=0.813, Patience=-50, Utilization=0, Grad Norm=0.975]                         \n",
      "[2025-09-21 03:31:05,646] INFO - Initial Validation Loss: 1.1533559477498656 Best Validation Loss: 0.813131201035461 Total Steps: 101 Best Step: 100 Total Time Spent: 1607.126315832138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6478126380910296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   7%|▋         | 7/100 [01:03<16:28, 10.63s/it, Best Val. Loss=1.06, Best Val. Score=-1.06, Training Loss=1.16, Val. Loss=1.06, Patience=44, Utilization=0, Grad Norm=1.67] [2025-09-21 03:34:13,680] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [23:55, 14.36s/it, Best Val. Loss=0.818, Best Val. Score=-0.818, Training Loss=0.846, Val. Loss=0.818, Patience=-49, Utilization=0, Grad Norm=0.981]                         \n",
      "[2025-09-21 03:56:58,003] INFO - Initial Validation Loss: 1.160625210789518 Best Validation Loss: 0.818443738526786 Total Steps: 101 Best Step: 100 Total Time Spent: 1442.7635006904602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6533362792752982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps: 101it [25:19, 15.20s/it, Best Val. Loss=0.822, Best Val. Score=-0.822, Training Loss=0.833, Val. Loss=0.822, Patience=-50, Utilization=0, Grad Norm=0.935]                         \n",
      "[2025-09-21 04:25:23,735] INFO - Initial Validation Loss: 1.159164211994054 Best Validation Loss: 0.8222821993148459 Total Steps: 101 Best Step: 100 Total Time Spent: 1522.6345643997192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.6464869642068052\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    train_len = int(len(dataset) * 0.8)\n",
    "    test_len = len(dataset) - train_len\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "    X_train = train_dataset.dataset.x[train_dataset.indices]\n",
    "    y_train = train_dataset.dataset.y[train_dataset.indices]\n",
    "    X_test = test_dataset.dataset.x[test_dataset.indices]\n",
    "    y_test = test_dataset.dataset.y[test_dataset.indices]\n",
    "    image_train = train_dataset.dataset.embeddings[train_dataset.indices]#.unsqueeze(1)\n",
    "    image_test = test_dataset.dataset.embeddings[test_dataset.indices]#.unsqueeze(1)\n",
    "\n",
    "    # if image_type == 'cls':\n",
    "    #     image_train = image_train.unsqueeze(1)\n",
    "    #     image_test = image_test.unsqueeze(1)\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_pad_ufes_20.ckpt\"\n",
    "    \n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=None,\n",
    "        image_train=image_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM+CQAM', # MGM, MGM+CQAM\n",
    "        mgm_heads=32,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM+CQAM', # MGM, MGM+CQAM\n",
    "        mgm_heads=32,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(None, image_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(None, image_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feafbe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6498895271763147\n",
      "Std Accuracy: 0.0054669650885417215\n"
     ]
    }
   ],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e43a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-21 04:41:22,525] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   2%|▏         | 2/100 [13:30<22:03:56, 810.57s/it, Best Val. Loss=1.4, Best Val. Score=-1.4, Training Loss=1.28, Val. Loss=1.4, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 05:02:59,817] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   3%|▎         | 3/100 [35:07<29:33:17, 1096.88s/it, Best Val. Loss=1.4, Best Val. Score=-1.4, Training Loss=1.32, Val. Loss=1.4, Patience=50, Utilization=0, Grad Norm=nan][2025-09-21 05:21:02,521] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:   4%|▍         | 4/100 [1:05:57<35:10:51, 1319.29s/it, Best Val. Loss=1.4, Best Val. Score=-1.4, Training Loss=1.25, Val. Loss=1.4, Patience=50, Utilization=0, Grad Norm=nan]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/random.py:179\u001b[0m, in \u001b[0;36mfork_rng\u001b[0;34m(devices, enabled, _caller, _devices_kw, device_type)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/utils/checkpoint.py:1400\u001b[0m, in \u001b[0;36m_checkpoint_without_reentrant_generator.<locals>.recompute_fn\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m device_autocast_ctx, torch\u001b[38;5;241m.\u001b[39mcpu\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcpu_autocast_kwargs), recompute_context:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1400\u001b[0m     \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/layer.py:449\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward\u001b[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001b[0m\n\u001b[1;32m    443\u001b[0m     state \u001b[38;5;241m=\u001b[39m layer_norm(\n\u001b[1;32m    444\u001b[0m         state,\n\u001b[1;32m    445\u001b[0m         allow_inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    446\u001b[0m         save_peak_mem_factor\u001b[38;5;241m=\u001b[39msave_peak_mem_factor,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[0;32m--> 449\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_norm:\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/layer.py:363\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_eval_pos:\n\u001b[0;32m--> 363\u001b[0m     new_x_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn_between_items\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_cache_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/multi_head_attention.py:355\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_cache \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    347\u001b[0m             batch_size,\n\u001b[1;32m    348\u001b[0m             seqlen_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    353\u001b[0m         )\n\u001b[0;32m--> 355\u001b[0m output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_k_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_v_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cached_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mreshape(x_shape_after_transpose[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/memory.py:100\u001b[0m, in \u001b[0;36msupport_save_peak_mem_factor.<locals>.method_\u001b[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_input:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/models/mmpfn_v2/model/multi_head_attention.py:513\u001b[0m, in \u001b[0;36mMultiHeadAttention._compute\u001b[0;34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    504\u001b[0m attention_head_outputs \u001b[38;5;241m=\u001b[39m MultiHeadAttention\u001b[38;5;241m.\u001b[39mcompute_attention_heads(\n\u001b[1;32m    505\u001b[0m     q,\n\u001b[1;32m    506\u001b[0m     k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_scale,\n\u001b[1;32m    512\u001b[0m )\n\u001b[0;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m... h d, h d s -> ... s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_head_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     29\u001b[0m save_path_to_fine_tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./finetuned_mmpfn_pad_ufes_20.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mfine_tune_mmpfn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# path_to_base_model=\"auto\",\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path_to_fine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Finetuning HPs\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetuning_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Input Data\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use \"cpu\" if you don't have a GPU\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optional\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_training_curve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows a final report after finetuning.\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shows all logs, higher values shows less\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Freeze the input layers (encoder and y_encoder) during finetuning\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMGM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# MGM, MGM+CQAM\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgm_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcqam_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# disables preprocessing at inference time to match fine-tuning\u001b[39;00m\n\u001b[1;32m     55\u001b[0m no_preprocessing_inference_config \u001b[38;5;241m=\u001b[39m ModelInterfaceConfig(\n\u001b[1;32m     56\u001b[0m     FINGERPRINT_FEATURE\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m     PREPROCESS_TRANSFORMS\u001b[38;5;241m=\u001b[39m[PreprocessorConfig(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/finetune_tabpfn_main.py:395\u001b[0m, in \u001b[0;36mfine_tune_mmpfn\u001b[0;34m(mixer_type, mgm_heads, cqam_heads, path_to_base_model, save_path_to_fine_tuned_model, time_limit, finetuning_config, validation_metric, categorical_features_index, task_type, device, y_train, X_train, image_train, use_multiple_gpus, multiple_device_ids, X_val, y_val, random_seed, logger_level, show_training_curve, freeze_input)\u001b[0m\n\u001b[1;32m    393\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    394\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 395\u001b[0m step_results \u001b[38;5;241m=\u001b[39m \u001b[43m_fine_tune_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X_image_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X_image_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_y_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_y_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_forward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_forward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Updated by the loop\u001b[39;49;00m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_with_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_now\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step_results\u001b[38;5;241m.\u001b[39moptimizer_step_skipped:\n\u001b[1;32m    414\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOptimizer step skipped due to NaNs/infs in grad scaling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/works/research/MultiModalPFN/mmpfn/scripts_finetune_mm/finetune_tabpfn_main.py:669\u001b[0m, in \u001b[0;36m_fine_tune_step\u001b[0;34m(batch_X_train, batch_X_test, batch_X_image_train, batch_X_image_test, batch_y_train, batch_y_test, device, model, optimizer, model_forward_fn, loss_fn, scaler, step_with_update, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m    667\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# Backward, Scaled for Mixed Precision\u001b[39;00m\n\u001b[0;32m--> 669\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Update\u001b[39;00m\n\u001b[1;32m    672\u001b[0m optimizer_step_skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/utils/checkpoint.py:1116\u001b[0m, in \u001b[0;36m_checkpoint_hook.__init__.<locals>.unpack_hook\u001b[0;34m(holder)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _recomputation_hook(\n\u001b[1;32m   1114\u001b[0m         weakref\u001b[38;5;241m.\u001b[39mref(frame), gid\n\u001b[1;32m   1115\u001b[0m     ), torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m-> 1116\u001b[0m         \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecompute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _StopRecomputationError:\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/utils/checkpoint.py:1388\u001b[0m, in \u001b[0;36m_checkpoint_without_reentrant_generator.<locals>.recompute_fn\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_rng_state \u001b[38;5;129;01mand\u001b[39;00m had_device_in_fwd:\n\u001b[1;32m   1387\u001b[0m     rng_devices \u001b[38;5;241m=\u001b[39m fwd_devices\n\u001b[0;32m-> 1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfork_rng(\n\u001b[1;32m   1389\u001b[0m     devices\u001b[38;5;241m=\u001b[39mrng_devices, enabled\u001b[38;5;241m=\u001b[39mpreserve_rng_state, device_type\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m   1390\u001b[0m ):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preserve_rng_state:\n\u001b[1;32m   1392\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_rng_state(fwd_cpu_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/random.py:183\u001b[0m, in \u001b[0;36mfork_rng\u001b[0;34m(devices, enabled, _caller, _devices_kw, device_type)\u001b[0m\n\u001b[1;32m    181\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_rng_state(cpu_rng_state)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device, device_rng_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(devices, device_rng_states):\n\u001b[0;32m--> 183\u001b[0m     \u001b[43mdevice_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_rng_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_rng_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/cuda/random.py:75\u001b[0m, in \u001b[0;36mset_rng_state\u001b[0;34m(new_state, device)\u001b[0m\n\u001b[1;32m     72\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[idx]\n\u001b[1;32m     73\u001b[0m     default_generator\u001b[38;5;241m.\u001b[39mset_state(new_state_copy)\n\u001b[0;32m---> 75\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/cuda/__init__.py:244\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/anaconda3/envs/mmpfn/lib/python3.10/site-packages/torch/cuda/random.py:73\u001b[0m, in \u001b[0;36mset_rng_state.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     idx \u001b[38;5;241m=\u001b[39m current_device()\n\u001b[1;32m     72\u001b[0m default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[idx]\n\u001b[0;32m---> 73\u001b[0m \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_copy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    train_len = int(len(dataset) * 0.8)\n",
    "    test_len = len(dataset) - train_len\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "    X_train = train_dataset.dataset.x[train_dataset.indices]\n",
    "    y_train = train_dataset.dataset.y[train_dataset.indices]\n",
    "    X_test = test_dataset.dataset.x[test_dataset.indices]\n",
    "    y_test = test_dataset.dataset.y[test_dataset.indices]\n",
    "    image_train = train_dataset.dataset.embeddings[train_dataset.indices]#.unsqueeze(1)\n",
    "    image_test = test_dataset.dataset.embeddings[test_dataset.indices]#.unsqueeze(1)\n",
    "\n",
    "    # if image_type == 'cls':\n",
    "    #     image_train = image_train.unsqueeze(1)\n",
    "    #     image_test = image_test.unsqueeze(1)\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_pad_ufes_20.ckpt\"\n",
    "    \n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=None,\n",
    "        image_train=image_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM', # MGM, MGM+CQAM\n",
    "        mgm_heads=64,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM', # MGM, MGM+CQAM\n",
    "        mgm_heads=64,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(None, image_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(None, image_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed520d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    train_len = int(len(dataset) * 0.8)\n",
    "    test_len = len(dataset) - train_len\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "    X_train = train_dataset.dataset.x[train_dataset.indices]\n",
    "    y_train = train_dataset.dataset.y[train_dataset.indices]\n",
    "    X_test = test_dataset.dataset.x[test_dataset.indices]\n",
    "    y_test = test_dataset.dataset.y[test_dataset.indices]\n",
    "    image_train = train_dataset.dataset.embeddings[train_dataset.indices]#.unsqueeze(1)\n",
    "    image_test = test_dataset.dataset.embeddings[test_dataset.indices]#.unsqueeze(1)\n",
    "\n",
    "    # if image_type == 'cls':\n",
    "    #     image_train = image_train.unsqueeze(1)\n",
    "    #     image_test = image_test.unsqueeze(1)\n",
    "        \n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_mmpfn_pad_ufes_20.ckpt\"\n",
    "    \n",
    "    fine_tune_mmpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=None,\n",
    "        image_train=image_train,\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"multiclass\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "        freeze_input=True,  # Freeze the input layers (encoder and y_encoder) during finetuning\n",
    "        mixer_type='MGM', # MGM, MGM+CQAM\n",
    "        mgm_heads=128,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = MMPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "        mixer_type='MGM', # MGM, MGM+CQAM\n",
    "        mgm_heads=128,\n",
    "        cqam_heads=8,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(None, image_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(None, image_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
