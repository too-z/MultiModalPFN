{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4c8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "\n",
    "from mmpfn.models.dino_v2.models.vision_transformer import vit_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7e4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_features = [\n",
    "    \"Age\",\n",
    "    \"Breed1\",\n",
    "    \"Breed2\",\n",
    "    \"Color1\",\n",
    "    \"Color2\",\n",
    "    \"Color3\",\n",
    "    \"Dewormed\",\n",
    "    \"Fee\",\n",
    "    \"FurLength\",\n",
    "    \"Gender\",\n",
    "    \"Health\",\n",
    "    \"MaturitySize\",\n",
    "    \"PhotoAmt\",\n",
    "    \"State\",\n",
    "    \"Sterilized\",\n",
    "    \"Type\",\n",
    "    \"Vaccinated\",\n",
    "    \"VideoAmt\",\n",
    "    \"Quantity\",\n",
    "]\n",
    "col_exclude = [\"PetID\", \"RescureID\", \"Description\", \"Name\"]\n",
    "col_target = \"AdoptionSpeed\"\n",
    "\n",
    "train = pd.read_csv(\"datasets/petfinder-adoption-prediction/train/train.csv\")\n",
    "datasets_dir = \"datasets/petfinder-adoption-prediction\"\n",
    "\n",
    "train[\"PetID\"] = train[\"PetID\"].astype(str)\n",
    "train_images = [\n",
    "    f\n",
    "    for f in os.listdir(os.path.join(datasets_dir, \"train_images\"))\n",
    "    if f.endswith(\".jpg\")\n",
    "]\n",
    "train_images = [f for f in train_images if f.split(\"-\")[0] in train[\"PetID\"].values]\n",
    "train_images_df = pd.DataFrame(\n",
    "    {\n",
    "        \"PetID\": [f.split(\"-\")[0] for f in train_images],\n",
    "        \"ImageNumber\": [f.split(\"-\")[1].split(\".\")[0] for f in train_images],\n",
    "    }\n",
    ")\n",
    "train_images_df = train_images_df[train_images_df[\"ImageNumber\"] == \"1\"]\n",
    "train = train.merge(train_images_df, on=\"PetID\", how=\"left\")\n",
    "train = train[train[\"ImageNumber\"].notna()]\n",
    "train[\"ImagePath\"] = train[\"PetID\"] + \"-1.jpg\"\n",
    "\n",
    "x_images = train[\"ImagePath\"]\n",
    "\n",
    "image_arrays = []\n",
    "for filename in x_images:\n",
    "    if filename.lower().endswith(\".jpg\"):\n",
    "        try:\n",
    "            with Image.open(\n",
    "                os.path.join(datasets_dir, \"train_images\", filename)\n",
    "            ) as img:\n",
    "                width, height = img.size\n",
    "                scale_factor = max(1.0, 224 / min(width, height))\n",
    "                new_width = ceil(width * scale_factor)\n",
    "                new_height = ceil(height * scale_factor)\n",
    "                new_width = ceil(new_width / 14) * 14\n",
    "                new_height = ceil(new_height / 14) * 14\n",
    "                img = img.resize((new_width, new_height), Image.BILINEAR)\n",
    "                image_arrays.append(np.array(img))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "for i, arr in enumerate(image_arrays):\n",
    "    if (arr.shape[0] % 14 != 0) or (arr.shape[1] % 14 != 0):\n",
    "        print(i, arr.shape)\n",
    "\n",
    "model = vit_small(\n",
    "    patch_size=14, img_size=518, init_values=1.0, num_register_tokens=0, block_chunks=0\n",
    ")\n",
    "\n",
    "model_path = \"parameters/dinov2_vits14_pretrain.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.cuda()\n",
    "\n",
    "image_features = []\n",
    "with torch.no_grad():\n",
    "    for image_array in image_arrays:\n",
    "        input_image = (\n",
    "            torch.tensor(np.expand_dims(np.transpose(img, (2, 0, 1)), axis=0))\n",
    "            .float()\n",
    "            .to(\"cuda\")\n",
    "        )\n",
    "        feat = model(input_image)\n",
    "        image_features.append(feat.cpu())\n",
    "        del input_image, feat\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "np.save(\"train_image_features_small.npy\", [t.numpy() for t in image_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2cb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
