{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8292ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/wall/works/research/MultiModalPFN/mmpfn/models/dino_v2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os \n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from mmpfn.datasets.cbis_ddsm import CBISDDSMDataset\n",
    "\n",
    "import os \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, root_mean_squared_error\n",
    "\n",
    "from mmpfn.models.tabpfn_v2 import TabPFNClassifier\n",
    "from mmpfn.models.dino_v2.models.vision_transformer import vit_base\n",
    "from mmpfn.models.tabpfn_v2.constants import ModelInterfaceConfig\n",
    "from mmpfn.models.tabpfn_v2.preprocessing import PreprocessorConfig\n",
    "from mmpfn.scripts_finetune.finetune_tabpfn_main import fine_tune_tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd5c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = os.path.join(os.getenv('HOME'), \"workspace/works/tabular_image/MultiModalPFN/mmpfn/data/cbis_ddsm\")\n",
    "data_path = os.path.join(os.getenv('HOME'), \"works/research/MultiModalPFN/mmpfn/data/cbis_ddsm\")\n",
    "\n",
    "kind = 'calc'  # mass calc\n",
    "image_type = 'all' # all full crop roi\n",
    "test_dataset = CBISDDSMDataset(data_path=data_path, data_name=f'csv/{kind}_case_description_test_set.csv', kind=kind, image_type=image_type)\n",
    "# _ = test_dataset.get_images()\n",
    "# _ = test_dataset.get_embeddings(mode='test')\n",
    "train_dataset = CBISDDSMDataset(data_path=data_path, data_name=f'csv/{kind}_case_description_train_set.csv', kind=kind, image_type=image_type)\n",
    "# _ = train_dataset.get_images()\n",
    "# _ = train_dataset.get_embeddings(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0144ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-17 23:50:15,221] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  31%|███       | 31/100 [00:08<00:18,  3.78it/s, Best Val. Loss=0.385, Best Val. Score=-0.385, Training Loss=0.411, Val. Loss=0.385, Patience=21, Utilization=0, Grad Norm=6.17][2025-09-17 23:50:23,329] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:27,  3.69it/s, Best Val. Loss=0.329, Best Val. Score=-0.329, Training Loss=0.422, Val. Loss=0.329, Patience=-48, Utilization=0, Grad Norm=5.25]                         \n",
      "[2025-09-17 23:50:42,029] INFO - Initial Validation Loss: 0.6356307716527124 Best Validation Loss: 0.32850282097971256 Total Steps: 101 Best Step: 100 Total Time Spent: 28.08517050743103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.7361963190184049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-17 23:50:42,861] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  31%|███       | 31/100 [00:08<00:18,  3.66it/s, Best Val. Loss=0.388, Best Val. Score=-0.388, Training Loss=0.422, Val. Loss=0.388, Patience=21, Utilization=0, Grad Norm=5.5] [2025-09-17 23:50:50,890] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  47%|████▋     | 47/100 [00:11<00:13,  4.07it/s, Best Val. Loss=0.365, Best Val. Score=-0.365, Training Loss=0.304, Val. Loss=0.365, Patience=6, Utilization=0, Grad Norm=4.23] [2025-09-17 23:50:54,795] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:25,  3.86it/s, Best Val. Loss=0.327, Best Val. Score=-0.327, Training Loss=0.422, Val. Loss=0.327, Patience=-47, Utilization=0, Grad Norm=5.93]                         \n",
      "[2025-09-17 23:51:08,575] INFO - Initial Validation Loss: 0.6356307716527124 Best Validation Loss: 0.3268209090066365 Total Steps: 101 Best Step: 94 Total Time Spent: 26.12501883506775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.7269938650306749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-17 23:51:09,325] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  31%|███       | 31/100 [00:07<00:18,  3.73it/s, Best Val. Loss=0.386, Best Val. Score=-0.386, Training Loss=0.413, Val. Loss=0.386, Patience=21, Utilization=0, Grad Norm=5.93][2025-09-17 23:51:17,174] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:26,  3.81it/s, Best Val. Loss=0.329, Best Val. Score=-0.329, Training Loss=0.411, Val. Loss=0.329, Patience=-48, Utilization=0, Grad Norm=4.67]                         \n",
      "[2025-09-17 23:51:35,393] INFO - Initial Validation Loss: 0.6356307716527124 Best Validation Loss: 0.3290179525979057 Total Steps: 101 Best Step: 99 Total Time Spent: 26.497071743011475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.7361963190184049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-17 23:51:36,137] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  31%|███       | 31/100 [00:07<00:18,  3.80it/s, Best Val. Loss=0.386, Best Val. Score=-0.386, Training Loss=0.417, Val. Loss=0.386, Patience=21, Utilization=0, Grad Norm=5.57][2025-09-17 23:51:44,051] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:26,  3.80it/s, Best Val. Loss=0.328, Best Val. Score=-0.328, Training Loss=0.417, Val. Loss=0.328, Patience=-48, Utilization=0, Grad Norm=4.7]                          \n",
      "[2025-09-17 23:52:02,271] INFO - Initial Validation Loss: 0.6356307716527124 Best Validation Loss: 0.3278344809926605 Total Steps: 101 Best Step: 100 Total Time Spent: 26.55355715751648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.7300613496932515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Steps:   1%|          | 1/100 [00:00<?, ?it/s][2025-09-17 23:52:03,061] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps:  31%|███       | 31/100 [00:08<00:18,  3.77it/s, Best Val. Loss=0.386, Best Val. Score=-0.386, Training Loss=0.417, Val. Loss=0.386, Patience=21, Utilization=0, Grad Norm=5.61][2025-09-17 23:52:11,083] INFO - \n",
      "Optimizer step skipped due to NaNs/infs in grad scaling.\n",
      "Fine-tuning Steps: 101it [00:27,  3.60it/s, Best Val. Loss=0.329, Best Val. Score=-0.329, Training Loss=0.415, Val. Loss=0.329, Patience=-48, Utilization=0, Grad Norm=4.69]                         \n",
      "[2025-09-17 23:52:30,588] INFO - Initial Validation Loss: 0.6356307716527124 Best Validation Loss: 0.32891966359035546 Total Steps: 101 Best Step: 100 Total Time Spent: 27.963973999023438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score (Finetuned): 0.7361963190184049\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # print(f\"Finetuning with seed: {seed}\")\n",
    "    \n",
    "    X_train = train_dataset.x\n",
    "    y_train = train_dataset.y\n",
    "    X_test = test_dataset.x\n",
    "    y_test = test_dataset.y\n",
    "\n",
    "    for i in range(X_train.shape[1]):\n",
    "        col = X_train[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "    for i in range(X_test.shape[1]):\n",
    "        col = X_test[:, i]\n",
    "        col[np.isnan(col)] = np.nanmin(col) - 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    save_path_to_fine_tuned_model = \"./finetuned_tabpfn_cbis_calc.ckpt\"\n",
    "    \n",
    "    fine_tune_tabpfn(\n",
    "        # path_to_base_model=\"auto\",\n",
    "        save_path_to_fine_tuned_model=save_path_to_fine_tuned_model,\n",
    "        # Finetuning HPs\n",
    "        time_limit=60,\n",
    "        finetuning_config={\"learning_rate\": 0.00001, \"batch_size\": 1, \"max_steps\": 100},\n",
    "        validation_metric=\"log_loss\",\n",
    "        # Input Data\n",
    "        X_train=pd.DataFrame(X_train),\n",
    "        y_train=pd.Series(y_train),\n",
    "        categorical_features_index=None,\n",
    "        device=\"cuda\",  # use \"cpu\" if you don't have a GPU\n",
    "        task_type=\"binary\",\n",
    "        # Optional\n",
    "        show_training_curve=False,  # Shows a final report after finetuning.\n",
    "        logger_level=0,  # Shows all logs, higher values shows less\n",
    "    )\n",
    "\n",
    "    # disables preprocessing at inference time to match fine-tuning\n",
    "    no_preprocessing_inference_config = ModelInterfaceConfig(\n",
    "        FINGERPRINT_FEATURE=False,\n",
    "        PREPROCESS_TRANSFORMS=[PreprocessorConfig(name='none')]\n",
    "    )\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    model_finetuned = TabPFNClassifier(\n",
    "        model_path=save_path_to_fine_tuned_model,\n",
    "        inference_config=no_preprocessing_inference_config,\n",
    "        ignore_pretraining_limits=True,\n",
    "    )\n",
    "\n",
    "    clf_finetuned = model_finetuned.fit(X_train, y_train)\n",
    "    acc_score = accuracy_score(y_test, clf_finetuned.predict(X_test))\n",
    "    print(\"accuracy_score (Finetuned):\", acc_score)\n",
    "    accuracy_scores.append(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2ba9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7331288343558283\n",
      "Std Accuracy: 0.0038800952885501365\n"
     ]
    }
   ],
   "source": [
    "# get mean and std of accuracy scores\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Std Accuracy:\", std_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297dfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Accuracy: 0.7527607361963191\n",
    "# Std Accuracy: 0.008366982636187638\n",
    "# Mean Accuracy: 0.7533742331288342\n",
    "# Std Accuracy: 0.00858895705521472"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
